{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Details\n",
    "\n",
    "The work is an attempt to build a CNN model to identify if the given X-ray image of chest in infected with Pneumonai or not. There are two categories of datasets that are covid patient with pneumonia and covid patient without pneumonia. The main objective is to improve Recall score because we would not want to miss the patient infected with Pneumonia and thus left untreated.\n",
    "Please follow the link to access the dataset : https://www.kaggle.com/rashikrahmanpritom/covid-wwo-pneumonia-chest-xray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import gc\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential\n",
    "import joblib\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tracing path of the image files\n",
    "# covid_with_pn=Path(\"E:\\DS Projects\\Deep_Learning\\Data\\train\\covid_with_PNEUMONIA\")\n",
    "# covid_without_pn=Path(\"E:\\DS Projects\\Deep_Learning\\Data\\train\\covid_without_PNEUMONIA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracing path of the image files\n",
    "covid_with_pn=Path(\"Data/train/covid_with_PNEUMONIA\")\n",
    "covid_without_pn=Path(\"Data/train/covid_without_PNEUMONIA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labelling training data images with Pneumonia as \"1\" and that of without Pneumonia as \"0\"\n",
    "w = 256; h=256\n",
    "images, labels=[],[]\n",
    "for i in covid_with_pn.glob(\"*.*\"):\n",
    "    data=image.load_img(i,target_size=(w, h),interpolation=\"bilinear\")\n",
    "    img=image.img_to_array(data)\n",
    "    images.append(img)\n",
    "    labels.append(1)\n",
    "\n",
    "for i in covid_without_pn.glob(\"*.*\"):\n",
    "    data=image.load_img(i,target_size=(w,h),interpolation=\"bilinear\")\n",
    "    img=image.img_to_array(data)\n",
    "    images.append(img)\n",
    "    labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_covid_with_pn=Path(\"Data/test/covid_with_PNEUMONIA\")\n",
    "test_covid_without_pn=Path(\"Data/test/covid_without_PNEUMONIA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labelling testing data images with Pneumonia as \"1\" and that of without Pneumonia as \"0\"\n",
    "test_images, test_labels=[],[]\n",
    "\n",
    "for i in test_covid_with_pn.glob(\"*.*\"):\n",
    "    data=image.load_img(i,target_size=(w,h),interpolation=\"bilinear\")\n",
    "    img=image.img_to_array(data)\n",
    "    test_images.append(img)\n",
    "    test_labels.append(1)\n",
    "    \n",
    "for i in test_covid_without_pn.glob(\"*.*\"):\n",
    "    data=image.load_img(i,target_size=(w,h),interpolation=\"bilinear\")\n",
    "    img=image.img_to_array(data)\n",
    "    test_images.append(img)\n",
    "    test_labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.array(images)/255\n",
    "y_train=np.array(labels)\n",
    "x_test=np.array(test_images)/255\n",
    "y_test=np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1568"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Building the Convolution Neural Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the f1 score of the model\n",
    "# def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "#     true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "#     possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "#     predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "#     precision = true_positives / (predicted_positives + K.epsilon())\n",
    "#     recall = true_positives / (possible_positives + K.epsilon())\n",
    "#     f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "#     return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(32,(3,3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(w,h,3)))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(64,(3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "# model.add(Conv2D(128,(3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "# model.add(MaxPooling2D((2,2)))\n",
    "model.add(Flatten())\n",
    "# model.add(Dropout(0.4))\n",
    "model.add(Dense(128,activation='relu',kernel_initializer='he_uniform'))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers=keras.optimizers.Adamax(learning_rate=0.01)\n",
    "model.compile(optimizer=optimizers, loss=\"binary_crossentropy\", metrics=['Precision', 'Recall', 'accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "45/45 [==============================] - 25s 551ms/step - loss: 54.6677 - precision: 0.7970 - recall: 0.8618 - accuracy: 0.8044 - val_loss: 0.2634 - val_precision: 0.8696 - val_recall: 0.9302 - val_accuracy: 0.8889\n",
      "Epoch 2/8\n",
      "45/45 [==============================] - 25s 547ms/step - loss: 0.3480 - precision: 0.9020 - recall: 0.8984 - accuracy: 0.8911 - val_loss: 0.2744 - val_precision: 0.9487 - val_recall: 0.8605 - val_accuracy: 0.9012\n",
      "Epoch 3/8\n",
      "45/45 [==============================] - 25s 547ms/step - loss: 0.2900 - precision: 0.9280 - recall: 0.8902 - accuracy: 0.9022 - val_loss: 1.0488 - val_precision: 1.0000 - val_recall: 0.3488 - val_accuracy: 0.6543\n",
      "Epoch 4/8\n",
      "45/45 [==============================] - 25s 546ms/step - loss: 0.1944 - precision: 0.9328 - recall: 0.9593 - accuracy: 0.9400 - val_loss: 0.1180 - val_precision: 0.9149 - val_recall: 1.0000 - val_accuracy: 0.9506\n",
      "Epoch 5/8\n",
      "45/45 [==============================] - 25s 552ms/step - loss: 0.1704 - precision: 0.9323 - recall: 0.9512 - accuracy: 0.9356 - val_loss: 0.0413 - val_precision: 0.9773 - val_recall: 1.0000 - val_accuracy: 0.9877\n",
      "Epoch 6/8\n",
      "45/45 [==============================] - 25s 550ms/step - loss: 0.1177 - precision: 0.9484 - recall: 0.9715 - accuracy: 0.9556 - val_loss: 0.0833 - val_precision: 0.9556 - val_recall: 1.0000 - val_accuracy: 0.9753\n",
      "Epoch 7/8\n",
      "45/45 [==============================] - 25s 549ms/step - loss: 0.0870 - precision: 0.9605 - recall: 0.9878 - accuracy: 0.9711 - val_loss: 0.1455 - val_precision: 0.9750 - val_recall: 0.9070 - val_accuracy: 0.9383\n",
      "Epoch 8/8\n",
      "45/45 [==============================] - 25s 558ms/step - loss: 0.0562 - precision: 0.9759 - recall: 0.9878 - accuracy: 0.9800 - val_loss: 0.1177 - val_precision: 0.9348 - val_recall: 1.0000 - val_accuracy: 0.9630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a440bd3b88>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train, batch_size = 10, epochs = 8, validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1579"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9662921348314606"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculated F1 score on validation data.\n",
    "f1_score(y_test,pred_lables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model performance on Validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[35,  3],\n",
       "       [ 0, 43]], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_lables=model.predict(x_test)\n",
    "pred_lables = pred_lables>0.5\n",
    "gc.collect()\n",
    "confusion_matrix(y_test, pred_lables.T[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model performance on Training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[201,   3],\n",
       "       [  2, 244]], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_lables_train=model.predict(x_train)\n",
    "pred_lables_train = pred_lables_train>0.5\n",
    "gc.collect()\n",
    "confusion_matrix(y_train, pred_lables_train.T[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
